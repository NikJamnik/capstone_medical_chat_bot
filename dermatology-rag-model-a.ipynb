{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T13:58:46.697970Z",
     "iopub.status.busy": "2025-04-16T13:58:46.697679Z",
     "iopub.status.idle": "2025-04-16T13:58:54.992637Z",
     "shell.execute_reply": "2025-04-16T13:58:54.991624Z",
     "shell.execute_reply.started": "2025-04-16T13:58:46.697947Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m581.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20250327->pdfplumber) (44.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber, faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0 pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n"
     ]
    }
   ],
   "source": [
    "# install necessary packages\n",
    "!pip install pdfplumber faiss-cpu transformers sentence-transformers nltk numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T13:58:54.993953Z",
     "iopub.status.busy": "2025-04-16T13:58:54.993609Z",
     "iopub.status.idle": "2025-04-16T13:59:18.889567Z",
     "shell.execute_reply": "2025-04-16T13:59:18.888425Z",
     "shell.execute_reply.started": "2025-04-16T13:58:54.993919Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 2.4 s, total: 17 s\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import pdfplumber\n",
    "import nltk\n",
    "import faiss \n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration\n",
    "import re\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T13:59:18.891394Z",
     "iopub.status.busy": "2025-04-16T13:59:18.890629Z",
     "iopub.status.idle": "2025-04-16T13:59:18.906611Z",
     "shell.execute_reply": "2025-04-16T13:59:18.905538Z",
     "shell.execute_reply.started": "2025-04-16T13:59:18.891363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_text_by_column(pdf_path): \n",
    "    # pdf_path: filepath of the textbook pdf document\n",
    "    \n",
    "    columns = [] # list to store text in, by column\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            # define boundaries of first and second columns\n",
    "            x0, y0, x1, y1 = page.bbox  # page boundaries\n",
    "            page_width = x1 - x0\n",
    "            page_height = y1 - y0\n",
    "\n",
    "            mid_x = x0 + (page_width / 2) # mid point of page\n",
    "\n",
    "            left_bbox = (x0, y0, mid_x, y1) # first column boundaries\n",
    "            right_bbox = (mid_x, y0, x1, y1) # second column boundaries\n",
    "\n",
    "            # extract text from each column\n",
    "            left_text = page.within_bbox(left_bbox).extract_text(x_tolerance=2, y_tolerance=2)\n",
    "            right_text = page.within_bbox(right_bbox).extract_text(x_tolerance=2, y_tolerance=2)\n",
    "\n",
    "            # add columns with text to list, with page number\n",
    "            for col_text in [left_text, right_text]:\n",
    "                if col_text and col_text.strip():\n",
    "                    columns.append({\"text\": col_text.strip(), \"page\": i + 1})\n",
    "    # return list of columns of text\n",
    "    return columns \n",
    "\n",
    "def chunk_text(columns, max_tokens=150, overlap_tokens=40): \n",
    "    # columns: list of columns from extract_text_by_column\n",
    "    # max_tokens: maxmium amount of tokens in a chunk\n",
    "    # overlap_tokens: number of tokens to overlap by between chunks\n",
    "\n",
    "    # create tokenizer \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    chunks = [] # list to store chunks of text as dictionaries with keys 'text' and 'page'\n",
    "\n",
    "    # divide each column of text into chunks\n",
    "    for col_chunk in columns:\n",
    "        # remove newline symbols from text\n",
    "        text = col_chunk['text'].replace('-\\n', '').replace('\\n', ' ') \n",
    "        page = col_chunk['page']\n",
    "        # tokenize by sentence\n",
    "        sentences = nltk.tokenize.sent_tokenize(text)\n",
    "\n",
    "        current_chunk = [] # current chunk to add sentences to \n",
    "        current_tokens = 0 # number of tokens in current chunk\n",
    "        overlap_chunk = []  # overlap tokens from previous chunk\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # encode the sentence\n",
    "            sentence_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "            \n",
    "            # check if adding the sentence will make the chunk too long\n",
    "            if current_tokens + len(sentence_tokens) <= max_tokens:\n",
    "                # if it isn't too long, add the sentence to the current chunk\n",
    "                current_chunk.append(sentence)\n",
    "                # update the chunk token count\n",
    "                current_tokens += len(sentence_tokens)\n",
    "                \n",
    "            else:\n",
    "                # if it is too long, add the current chunk to the chunks list and move on to the next chunk\n",
    "                chunks.append({'text': ' '.join(current_chunk), 'page': page})\n",
    "                \n",
    "                # tokenize the current chunk\n",
    "                tokenized_chunk = tokenizer.encode(' '.join(current_chunk), add_special_tokens=False)\n",
    "                if len(tokenized_chunk) > overlap_tokens:\n",
    "                    # go backwards through the chunk to get overlap tokens\n",
    "                    overlap_text = ''\n",
    "                    overlap_token_count = 0\n",
    "                    for s in reversed(current_chunk):\n",
    "                        # add sentences to next chunk, making sure to stay under the overlap amount\n",
    "                        s_tokens = tokenizer.encode(s, add_special_tokens=False)\n",
    "                        if overlap_token_count + len(s_tokens) > overlap_tokens:\n",
    "                            break\n",
    "                        overlap_text = s + ' ' + overlap_text\n",
    "                        overlap_token_count += len(s_tokens)\n",
    "                    # start next chunk with overlap tokens\n",
    "                    current_chunk = [overlap_text.strip()]\n",
    "                    current_tokens = overlap_token_count\n",
    "                else:\n",
    "                    # if the previous chunk is too small, don't overlap\n",
    "                    current_chunk = []\n",
    "                    current_tokens = 0\n",
    "\n",
    "                # add the sentence to the current chunk\n",
    "                current_chunk.append(sentence)\n",
    "                current_tokens += len(sentence_tokens)\n",
    "            \n",
    "        if current_chunk:\n",
    "            # if there is a final chunk left, add it to the chunks list\n",
    "            chunks.append({'text': ' '.join(current_chunk), 'page': page})\n",
    "\n",
    "    # return list of chunks\n",
    "    return chunks\n",
    "\n",
    "def get_faiss_index(chunks, embed_model=\"all-MiniLM-L6-v2\"):\n",
    "    # chunks: list of chunks from chunk_text\n",
    "    # embed_model: model to use for vector embedding\n",
    "\n",
    "    # create embedding model\n",
    "    model = SentenceTransformer(embed_model)\n",
    "    \n",
    "    texts = [chunk['text'] for chunk in chunks] # text from each chunk in chunks\n",
    "    page_numbers =  [chunk['page'] for chunk in chunks] # page from each chunk in chucks\n",
    "    # use model to embed chunk texts\n",
    "    embeddings = model.encode(texts)\n",
    "    dim = embeddings.shape[1] # dimension of embeddings\n",
    "\n",
    "    # create FAISS index\n",
    "    faiss_index = faiss.IndexFlatL2(dim)\n",
    "    # add embeddings to index\n",
    "    faiss_index.add(np.array(embeddings))\n",
    "\n",
    "    # return index with embeddings and list of chunks\n",
    "    return faiss_index, chunks\n",
    "\n",
    "def retrieve_context(faiss_index, chunks, query, embed_model=\"all-MiniLM-L6-v2\", threshold=0.5,  k=2):\n",
    "    # faiss_index: FAISS index of embeddings from get_faiss_index\n",
    "    # chunks: list of chunks from get_faiss_index\n",
    "    # embed_model: model to use for vector embedding\n",
    "    # threshold: minimum similarity between query and relevant chunk\n",
    "    # k: number of chunks to retrieve\n",
    "    \n",
    "    # set device to cuda GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "    # create embedding model\n",
    "    model = SentenceTransformer(embed_model).to(device)\n",
    "    # use model to embed query\n",
    "    query_embedding = model.encode([query])[0].reshape(1, -1)\n",
    "\n",
    "    # get the distances and ids of nearest k chunks to query\n",
    "    distances, retrieved_ids = faiss_index.search(query_embedding, k)\n",
    "    # convert distances to similarities to normalize\n",
    "    similarities = 1/(1+distances[0])\n",
    "\n",
    "    retrieved_chunks = [] # list of chunks to return\n",
    "    # check if each chunk has a similarity above the threshold and is longer than five words\n",
    "    for i, idx in enumerate(retrieved_ids[0]):\n",
    "        chunk_text = chunks[idx]\n",
    "        similarity = similarities[i]\n",
    "        if similarity>threshold and len(chunk_text['text'].split())>=5:\n",
    "            # add chunks that meet the criteria\n",
    "            retrieved_chunks.append((chunk_text, similarity))\n",
    "\n",
    "    # return list of retrieved chunks\n",
    "    return retrieved_chunks\n",
    "\n",
    "\n",
    "def answer_query(query, context, qa_model=\"google/flan-t5-large\"):\n",
    "    # query: user input question\n",
    "    # context: retrieved_chunks from retrieve_context\n",
    "    # qa_model: LLM to use for question answering\n",
    "\n",
    "    # set device to cuda GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "    # create tokenizer and model\n",
    "    tokenizer = T5Tokenizer.from_pretrained(qa_model)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(qa_model).to(device) \n",
    "\n",
    "    context_text = [chunk[0]['text'] for chunk in context][0] # text from most relevant chunk in context\n",
    "\n",
    "    # combine prompt, query, and relevant context\n",
    "    input_text = f\"Answer the question. Do not simply return a word or fragment, but one or more complete and detailed sentences, including all necessary information and all relevant context.: \\n \\n{query}\\n\\nContext:\\n{context_text}\"\n",
    "\n",
    "    # tokenize input text for LLM \n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding='max_length',max_length=1000, truncation=True).to(device) \n",
    "    # set random seed\n",
    "    torch.manual_seed(42)\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    # pass inputs to LLM to generate response\n",
    "    outputs = model.generate(**inputs, max_new_tokens=1500, do_sample=True, \n",
    "                           temperature=0.7, top_p=0.9, early_stopping=True, num_beams=3)\n",
    "    # decode output to get answer in text\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # return text answer\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T13:59:18.909407Z",
     "iopub.status.busy": "2025-04-16T13:59:18.908981Z",
     "iopub.status.idle": "2025-04-16T14:00:20.249961Z",
     "shell.execute_reply": "2025-04-16T14:00:20.249222Z",
     "shell.execute_reply.started": "2025-04-16T13:59:18.909387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac070a5c15d942bc8e95335b29881462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca074ea2a15c4f1c801baffe3575d63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bba805fde7473185c96430a764ab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221b5f847f574992a73d080ba18dbae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.8 s, sys: 2.09 s, total: 59.9 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "filepath = 'ClinicalDermatology.pdf' # filepath of textbook pdf\n",
    "# read in textbook data and divide into \"chunks\"\n",
    "chunks = chunk_text(extract_text_by_column(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:00:20.252725Z",
     "iopub.status.busy": "2025-04-16T14:00:20.252357Z",
     "iopub.status.idle": "2025-04-16T14:00:36.257923Z",
     "shell.execute_reply": "2025-04-16T14:00:36.257116Z",
     "shell.execute_reply.started": "2025-04-16T14:00:20.252694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69397082d0cf4d3fb4523255e2327c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b96cf2f52ed4a3c8aa25afdc7123895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521635bc394f4aadabcd22173d43895f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c944cfd45e43f886178275fbcfc2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed93ab18939f42c28f5f39a4810267b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46a6fe2fc764d5c82b10376c6ee59ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96048069b22494e9b3133a7461a4492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a4cd52cfba48cd83f09a979a66bad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 684 ms, total: 5.2 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "# represent chunks of text as vector embeddings\n",
    "faiss_index, chunks = get_faiss_index(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:00:36.259069Z",
     "iopub.status.busy": "2025-04-16T14:00:36.258791Z",
     "iopub.status.idle": "2025-04-16T14:00:36.265035Z",
     "shell.execute_reply": "2025-04-16T14:00:36.263918Z",
     "shell.execute_reply.started": "2025-04-16T14:00:36.259045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# manually create test set by reading through textbook and coming up with questions:\n",
    "test_qa = [\n",
    "    (\"What is dermatology?\", \"Dermatology is the study of skin and its associated structures, including the hair and the nails and their diseases.\"),\n",
    "    (\"Name the five Ds of dermatological disease.\", \"The five Ds are Disfigurement, Disablement, Discomfort, Death and Depression\"),\n",
    "    (\"How many layers does skin have?\", \"Skin has two layers, the outer epidermis and the underlying dermis.\"),\n",
    "    (\"Explain the difference between a nodule and a tumor.\", \"A nodule is a solid mass in the skin greater than 0.5cm in diameter. A tumor is less clearly defined, but is typically more than 1cm in diameter. Tumors can also be called 'large nodules'.\"),\n",
    "    (\"How is a potential fungal infection tested?\", \"Scales or plucked hairs can be dissolved into an aqueous solution of 20% potassium hydroxide (KOH) containing 40% dimethyl sulphoxide (DMSO). The scale from the edge of a scaling lesion is vigorously scraped on to a glass slide with a No. 15 scalpel blade or the edge of a second glass slide. A drop or two of the KOH solution is run under the cover slip. After 5-10 min the mount is examined under a microscope with the condenser lens lowered to increase contrast.\"),\n",
    "    (\"What kind of diagnosis is Tanzck smear used in?\", \"Tanzck smear, or cytology, can aid in diagnosis of viral infections such as herpes simplex and zoster, and of bullous diseases such as pemphigus.\"),\n",
    "    (\"When should you use incisional vs. excisional biopsies?\", \"Excisional biopsy is preferable for most small lesions (up to 0.5 cm diameter) but incisional biopsy is chosen when the partial removal of a larger lesion is adequate for diagnosis, and complete removal might leave an unnecessary and unsightly scar.\"),\n",
    "    (\"How does psoriasis affect the scalp?\", \"Areas of scaling are interspersed with normal skin; their lumpiness is more easily felt than seen.  Frequently, the psoriasis overflows just beyond the scalp margin. Significant hair loss is rare.\"),\n",
    "    (\"What causes Lyell's Disease?\", \"Toxic epidermal necrolysis (Lyell's disease) is usually a drug reaction, most commonly to sulphonamides, barbituates, carbamazepine, or allopurinol, but can also be a manifestation of graft-vs.-host disease.\"),\n",
    "    (\"What other conditions can systemic lupus erythematosus be confused with?\", \"SLE is a great imitator. Its malar rash can be confused with sunburn, polymorphic light eruption, and rosacea. The discoid lesions are distinctive, but are also seen in discoid LE and in subacute cutaneous LE. Occasionally they look like psoriasis or lichen planus. The hair fall suggests telogen effluvium.\"),\n",
    "    (\"Describe the symptoms of Acrocyanosis.\", \"The hands, feet, nose, ears, and cheeks become blue-red and cold. The palms are often cold and clammy.\"),\n",
    "    (\"How can Raynaud's disease be treated?\", \"The main treatment is to protect the vulnerable digits from cold. Warm clothing reduces the need for peripheral vasoconstriction to conserve heat. Smoking should be abandoned. Calcium channel blockers (e.g. nifedipine 10-30 mg three time daily) are the most effective in parients with primary Raynaud's disease.\"),\n",
    "    (\"How is Doxycycline different from Minocycline?\", \"It is a cheaper alternative to minocycline, but more frequently associated with phototoxic skin reactions.\"),\n",
    "    (\"Are Tetracyclines safe for children?\", \"No, Tetracyclines should not be taken by children under 12 years as they are deposited in growing bone and developing teeth, causing stained teeth and dental hypoplasia.\"),\n",
    "    (\"Where in the body are sweat glands?\", \"There are 2-3 million sweat glands distributed all over the body surface, but they are most numerous on the palms, soles, and axillae.\"),\n",
    "    (\"Describe the phases of the hair cycle.\", \"There are three phases of follicular activity. 1 Anagen. The active phase of hair production. 2 Catagen. A short phase of conversion from active growth to the resting phase. Growth stops, and the end of the hair becomes club-shaped. 3 Telogen. A resting phase at the end of which the club hair is shed.\"),\n",
    "    (\"What condition results from a cat bite?\", \"The infective agent is the baccilus Rochalimaea henselae. A few days after a cat bite or scratch, a reddish granulomatous papule appears at the site of inoculation.\"),\n",
    "    (\"How is syphilis diagnosed?\", \"The diagnosis of syphilis in its infectious (primary and secondary) stages can be confirmed using dark field microscopy to show up spirochaetes in smears from chancres, oral lesions, or moist areas in a secondary eruption. Serological tests for syphilis become positive only some 5–6 weeks after infection (usually a week or two after the appearance of the chancre). The traditional tests [Wasswemann reaction (WR) and Venereal Disease Research Laboratory (VDRL)] have now been replaced by more specific ones [e.g. the rapid plasma reagin (RPR) test and the fluorescent treponemal antibody/absorption (FTA/ABS) test]. These more sensitive tests do not become negative after treatment if an infection has been present for more than a few months.\"),\n",
    "    (\"Is dapsone an effective treatment for leprosy?\", \"The emergence of resistant strains of M. leprae means that it is no longer wise to treat leprosy with dapsone alone. It should now be used in combination, usually with clofazimine for lepromatous leprosy.\"),\n",
    "    (\"What causes hair to turn grey early?\", \"Early greying of the hair is seen in the rare premature aging syndromes, such as Werner's syndrome, and in autoimmune conditions such as pernicious anaemia, thyroid disorders, and Addison's disease.\"),\n",
    "    (\"Explain dermatological non-disease.\", \"This is a form of dysmorphophobia. The clinician can find no abnormality, but the distress felt by the patient leads to anxiety, depression, or even sucicide. Such patients are not uncommon. They expect dermatological solutions for complaints such as hair loss, or burning, itching, and redness of the face or genitals. The dermatologist, who can see nothing wrong, cannot solve matters and no treatment seems to help.\"),\n",
    "    (\"Which drugs can cause toxic reactive erythema?\", \"Culprits include antibiotics (especially ampicillin), sulphonamides and related compounds (diuretics and hypoglycaemics), barbituates, phenylbutazone, and para-aminosalicylate (PAS).\"),\n",
    "    (\"What conditions does cryotherapy treat?\", \"It is effective for viral warts, seborrhoeic keratoses, actinic keratoses, and some superficial skin tumors (e.g. intraepidermal carcinoma and lentigo maligna.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:00:36.266388Z",
     "iopub.status.busy": "2025-04-16T14:00:36.266147Z",
     "iopub.status.idle": "2025-04-16T14:03:10.602911Z",
     "shell.execute_reply": "2025-04-16T14:03:10.602147Z",
     "shell.execute_reply.started": "2025-04-16T14:00:36.266354Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09baac5c6e8344ed90551ca9ebcb67a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6991adc2336948de92258b3666583533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35766e131be442b98f31d55e9f64273e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0010e02b18e4612aa21f8617a0e0a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a35b97fd9848be8755415bad8cb6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f158563231549a487c88a91673a2904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06e2dc4007346809dd9001f9a1937eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccc221362e34ca8aba05e49148e5851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d371e620e34ec48787a8b580959d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8199c079593a4029a0df1872068302f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf10a1f3bfd46dd819ee16a2a05da2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f6592354d14f14a30bcc4592d191d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b37eb25e0e94bdd9be68f571afcad36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a76052f09440579d874620de9a401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059f1c8233db48029381adcf9c27a528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2708f01ecdc44cd69110623d094ef864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4135f8025c8445699347047b72f8edf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff18e6c1738342a3bcaa1d9ad5fb2582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2b78675eb84315949e0ffeb53c1d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34f0e4d33ad4b448500bf3a260befcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a22fbcb63a41c386d74241070165c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25946be048e946f1bbd06fad065cef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ade47162c346b396f58a763c49fe38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857c8f2fd4e64ebcb84b2289b7e7b4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b8030c55834f28a51068daeec454a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa620896414b4ba0ae2d092e1ae024e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926c8463e4be43898728d2e6d98b66ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66189e44a644ba08d866df8275d5214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ce56def4be4f79889ca2e2065eb827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1e3ea255574cfe824be6e68d2dee0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dicts = [] # list of dictionaries to contain query, truth, context, and answer for test set data\n",
    "for i in range(len(test_qa)):\n",
    "    # retreive context for query i\n",
    "    context = retrieve_context(faiss_index, chunks, test_qa[i][0], k=3, threshold=0.4)\n",
    "    # add current query, truth, context, and answer to eval_dicts\n",
    "    eval_dicts.append({\n",
    "        'query': test_qa[i][0],\n",
    "        'truth': test_qa[i][1],\n",
    "        'context':  context,\n",
    "        'answer': answer_query(test_qa[i][0], context) # generate answer \n",
    "        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:03:10.604775Z",
     "iopub.status.busy": "2025-04-16T14:03:10.604416Z",
     "iopub.status.idle": "2025-04-16T14:03:10.610632Z",
     "shell.execute_reply": "2025-04-16T14:03:10.609748Z",
     "shell.execute_reply.started": "2025-04-16T14:03:10.604738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create evaluation metrics:\n",
    "\n",
    "def context_precision(truth, context): # input the ground truth and the retreived documents\n",
    "    text = ''.join(context[0][0]['text']) # text of context used\n",
    "    # create Tfidf vectorizer and fit to both truth and context\n",
    "    vectorizer = TfidfVectorizer().fit([context[0][0]['text'], truth])\n",
    "    # vectorize both truth and context\n",
    "    vectors = vectorizer.transform([context[0][0]['text'], truth])\n",
    "    # get cosine similarity between truth and context vectors\n",
    "    sim = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return sim\n",
    "\n",
    "def faithfulness(answer, context): # input the generated answer and the retrieved documents\n",
    "    text = ''.join(context[0][0]['text']) # text of context used\n",
    "    # create Tfidf vectorizer and fit to both answer and context\n",
    "    vectorizer = TfidfVectorizer().fit([answer, context[0][0]['text']])\n",
    "    # vectorize both answer and context\n",
    "    vectors = vectorizer.transform([answer, context[0][0]['text']])\n",
    "    # get cosine similarity between answer and context vectors\n",
    "    sim = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:03:10.611909Z",
     "iopub.status.busy": "2025-04-16T14:03:10.611588Z",
     "iopub.status.idle": "2025-04-16T14:03:10.773414Z",
     "shell.execute_reply": "2025-04-16T14:03:10.772446Z",
     "shell.execute_reply.started": "2025-04-16T14:03:10.611878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Precision:  0.4149936306095072 Faithfulness:  0.5114133579400361\n"
     ]
    }
   ],
   "source": [
    "cp = [] # list of context precisions\n",
    "f = [] # list of faithfulnesses\n",
    "\n",
    "for x in eval_dicts:\n",
    "    # calculate and metrics for each item in eval_dicts and add metrics to lists\n",
    "    cp.append(context_precision(x['truth'], x['context']))\n",
    "    f.append(faithfulness(x['answer'], x['context']))\n",
    "    \n",
    "# calculate means of each list\n",
    "print('Context Precision: ', np.mean(cp), 'Faithfulness: ', np.mean(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:03:10.774718Z",
     "iopub.status.busy": "2025-04-16T14:03:10.774407Z",
     "iopub.status.idle": "2025-04-16T14:03:11.649603Z",
     "shell.execute_reply": "2025-04-16T14:03:11.648708Z",
     "shell.execute_reply.started": "2025-04-16T14:03:10.774693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfb7c1cced4452fafae28b038e1a75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 140 ms, sys: 18.1 ms, total: 158 ms\n",
      "Wall time: 870 ms\n"
     ]
    }
   ],
   "source": [
    "# example query:\n",
    "query = \"what is psoriasis?\"\n",
    "# search for documents relevant to query\n",
    "context1 = retrieve_context(faiss_index, chunks, query, k=3, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:03:11.650742Z",
     "iopub.status.busy": "2025-04-16T14:03:11.650483Z",
     "iopub.status.idle": "2025-04-16T14:03:16.397635Z",
     "shell.execute_reply": "2025-04-16T14:03:16.396896Z",
     "shell.execute_reply.started": "2025-04-16T14:03:11.650719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.95 s, sys: 395 ms, total: 4.34 s\n",
      "Wall time: 4.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It is a chronic non-infectious inflammatory skin disorder, characterized by well-defined erythematous plaques bearing large adherent silvery scales.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# provide relevant documents to question answering LLM to get answer\n",
    "answer_query(query, context1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7006360,
     "sourceId": 11219204,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
